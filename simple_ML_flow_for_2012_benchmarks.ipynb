{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import sys\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(svc_obj, df_in_test, df_target_test):\n",
    "    predicted_result=svc_obj.predict(df_in_test)\n",
    "    predicted_result_list = predicted_result.tolist()\n",
    "    target_values_list = df_target_test.values.tolist()\n",
    "    \n",
    "    true_hotspot_count = np.sum(target_values_list)\n",
    "    true_non_hotspot_count = len(target_values_list)-true_hotspot_count\n",
    "    hotspot_hit=0\n",
    "    non_hotspot_hit=0\n",
    "    extra_fp=0\n",
    "    extra_fn=0\n",
    "\n",
    "    for i in range(len(predicted_result_list)):\n",
    "        #accuracy - hotspot being called as a hotspot\n",
    "        if (target_values_list[i] == 1) and (predicted_result_list[i] == 1):\n",
    "            hotspot_hit = hotspot_hit +1\n",
    "        #false positives - non-hotpsot pattern classified as a hotspot\n",
    "        elif (target_values_list[i] == 0) and (predicted_result_list[i] == 1):\n",
    "            extra_fp = extra_fp + 1\n",
    "        #false negatives - a hotspot pattern classified as a non-hotspot    \n",
    "        elif (target_values_list[i] == 1) and (predicted_result_list[i] == 0):\n",
    "            extra_fn = extra_fn + 1\n",
    "        #accuracy - a non-hotspot pattern classified as a non-hotspot    \n",
    "        elif (target_values_list[i] == 0) and (predicted_result_list[i] == 0):\n",
    "            non_hotspot_hit = non_hotspot_hit + 1\n",
    "        else:\n",
    "            print ('****** ERROR: unknown result values ******')\n",
    "            sys.exit(0)\n",
    "    result_print_str = \"\"\n",
    "    result_print_str += \"****** Results ******\\n\"\n",
    "    result_print_str += \"hotspot hit = {}\\n\".format(hotspot_hit)\n",
    "    result_print_str += \"non-hotspot hit = {}\\n\".format(non_hotspot_hit)\n",
    "    result_print_str += \"false positives = {}\\n\".format(extra_fp)\n",
    "    result_print_str += \"false negatives = {}\\n\".format(extra_fn)\n",
    "    result_print_str += \"Total hotspots in test set = {}\\n\".format(true_hotspot_count)\n",
    "    result_print_str += \"Total non-hotspots in test set = {}\\n\".format(true_non_hotspot_count)\n",
    "    if true_hotspot_count!=0 :result_print_str += \"hotspot hit rate = {}%\\n\".format(np.round((float(hotspot_hit)/true_hotspot_count)*100, 2))\n",
    "    result_print_str +=\"false alarm rate = {}%\\n\".format(np.round((float(extra_fp)/true_non_hotspot_count)*100, 2))\n",
    "    \n",
    "    return result_print_str\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def run_analysis(complete_training_df, complete_testing_df):\n",
    "    if not test_only:\n",
    "        train_df_name=complete_training_df.name\n",
    "        #shuffle the input train df\n",
    "        complete_training_df = shuffle(complete_training_df)\n",
    "        if complete_training_df.isnull().values.any():\n",
    "            print \"**** Error: The training set has some Nan values **** - \", train_df_name \n",
    "\n",
    "        df_target_train=complete_training_df.pop(\"Litho_result\")\n",
    "        df_in_train=complete_training_df.copy() # already result has been removed\n",
    "\n",
    "    df_target_test=complete_testing_df.pop(\"Litho_result\")\n",
    "    df_in_test=complete_testing_df.copy() # already result has been removed\n",
    "\n",
    "    if not test_only:\n",
    "        # fit the model\n",
    "        print \"Training started ---\", datetime.now(), \"--Training dataset size - \", df_in_train.shape, \"-\", train_df_name\n",
    "        train_start_time = datetime.now()\n",
    "        clf.fit(df_in_train, df_target_train)\n",
    "        train_end_time = datetime.now()\n",
    "        print \"----Training Completed----\", datetime.now(), \"-\", train_df_name\n",
    "\n",
    "        #pickle the necessary items    \n",
    "        if retrain_and_save_models:\n",
    "            try:\n",
    "                with open(model_path+\"trained_model.pkl\", 'wb') as f:  \n",
    "                    pickle.dump([clf], f, protocol=-1)\n",
    "                    print \"---- Trained model saved at {} ----\".format(model_path), datetime.now(), \"-\", train_df_name\n",
    "            except Exception as e:\n",
    "                sys.exit(\"*** ERROR: Unable to save pickle file,  with exception - {}\".format(e))\n",
    "            \n",
    "            \n",
    "    #Test set prediction           \n",
    "    print \"Test set prediction started --- test dataset size - \", df_in_test.shape\n",
    "    testset_result_print_str = predict(clf, df_in_test, df_target_test)\n",
    "    print \"----Predict test set completed----\", datetime.now()    \n",
    "    print testset_result_print_str\n",
    "    if not test_only:\n",
    "        print 'Total training time: {}'.format(train_end_time - train_start_time), \"-\", train_df_name\n",
    "    print 'Total run time: {}'.format(datetime.now() - prog_start_time)\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Run main code\n",
    "===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     11,
     15,
     21,
     32,
     40,
     54,
     61
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Testing Dataset used -- ./test_dataset/array_benchmark5_named_.csv\n",
      "complete_testing_df size -  (2152, 1601)\n",
      "Test set prediction started --- test dataset size -  (2152, 1600)\n",
      "----Predict test set completed---- 2019-04-25 18:16:11.527186\n",
      "****** Results ******\n",
      "hotspot hit = 41\n",
      "non-hotspot hit = 2107\n",
      "false positives = 4\n",
      "false negatives = 0\n",
      "Total hotspots in test set = 41\n",
      "Total non-hotspots in test set = 2111\n",
      "hotspot hit rate = 100.0%\n",
      "false alarm rate = 0.19%\n",
      "\n",
      "Total run time: 0:00:09.982941\n"
     ]
    }
   ],
   "source": [
    "retrain_and_save_models = False # if True: train locally and save models at model_path. if False: pre-trained models from model_path will be used\n",
    "model_path = \"./trained_models/28nm/\" #Use 32nm models for testing array_benchmark1, 28nm models for the rest\n",
    "#all training datasets from the same node are combined and trained once, then, using the common trained model, testing datasets are tested individually\n",
    "train_df_paths = [\"./train_dataset/MX_Benchmark2_clip_named_.csv\",\\\n",
    "                  \"./train_dataset/MX_Benchmark3_clip_named_.csv\", \\\n",
    "                  \"./train_dataset/MX_Benchmark4_clip_named_.csv\", \\\n",
    "                  \"./train_dataset/MX_Benchmark5_clip_named_.csv\"]\n",
    "test_df_path = \"./test_dataset/array_benchmark5_named_.csv\"\n",
    "            \n",
    "#------------------------------ No user modifications needed below this line ------------------------\n",
    "\n",
    "if retrain_and_save_models:\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    test_only=False\n",
    "else:\n",
    "    test_only=True\n",
    "\n",
    "prog_start_time = datetime.now()\n",
    "global clf\n",
    "\n",
    "if not test_only:\n",
    "    # create training dataframes - Mx benchmarks\n",
    "    train_df = pd.DataFrame()\n",
    "    for path in train_df_paths:\n",
    "        temp_df = pd.read_csv(path, header = 0, index_col = 0)\n",
    "        train_df = train_df.append(temp_df, ignore_index=False)[temp_df.columns]\n",
    "\n",
    "# create test dataframes - Array benchmarks\n",
    "print \"-- Testing Dataset used --\", test_df_path\n",
    "test_df = pd.read_csv(test_df_path, header = 0, index_col = 0)\n",
    "\n",
    "if not test_only:\n",
    "    complete_train_hotspot_df = train_df[train_df['Litho_result']==1]\n",
    "    complete_train_non_hotspot_df = train_df[train_df['Litho_result']==0]\n",
    "    complete_train_df = pd.concat([complete_train_hotspot_df, complete_train_non_hotspot_df], ignore_index=False)\n",
    "\n",
    "complete_testing_df = test_df\n",
    "print \"complete_testing_df size - \", complete_testing_df.shape\n",
    "\n",
    "if not test_only:\n",
    "    #compute weights\n",
    "    hotspot_count = len(complete_train_hotspot_df)\n",
    "    non_hotspot_count = len(complete_train_non_hotspot_df)\n",
    "    hotspot_weight = len(complete_train_df)/(2.0*hotspot_count) # n_samples/(n_clases*class_sample_count)\n",
    "    non_hotspot_weight = len(complete_train_df)/(2.0*non_hotspot_count)\n",
    "    norm_hotspot_weight = hotspot_weight/(hotspot_weight+non_hotspot_weight)\n",
    "    norm_non_hotspot_weight = non_hotspot_weight/(hotspot_weight+non_hotspot_weight)\n",
    "    \n",
    "    C_val = 6 # obtained through cross-validation\n",
    "    gamma_val=0.003 #obtained through cross validation\n",
    "\n",
    "    clf = svm.SVC(C=C_val, degree=3, gamma=gamma_val, kernel='rbf', verbose=True,cache_size=40000, class_weight={0:norm_non_hotspot_weight+0.01, 1:norm_hotspot_weight+0.04}) #weight bias values obtained through cross-validation\n",
    "    complete_train_df.name=\"train_df\"\n",
    "else: # use a pre-trained model\n",
    "    try:\n",
    "        with open(model_path+\"trained_model.pkl\", 'rb') as f:    \n",
    "            clf = pickle.load(f)[0]\n",
    "    except Exception as e:\n",
    "        sys.exit(\"*** ERROR: Unable to read a pkl file, with exception - {}\".format(e)) \n",
    "\n",
    "if test_only:\n",
    "    complete_train_df = pd.DataFrame()\n",
    "\n",
    "run_analysis(complete_train_df, complete_testing_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
